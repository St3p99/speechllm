data:
  data_path: "/net/tscratch/people/plgstefanop/data/parler_tts/LibriTTS-R-Filtered"
  split: "train_full"
  amount: ":100%"
  sampling_rate: 16000
  min_duration: 0.01
  max_duration: 15.0
  num_proc_for_preprocessing: 4
  remap_keys: {"text_normalized": "transcription"}

training:
  output_dir: /net/tscratch/people/plgstefanop/speechllm/speechllm/output/paper
  num_train_epochs: 5
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 2
  learning_rate: 1e-4
  lr_scheduler_type: cosine
  warmup_steps: 1000
  bf16: true
  save_strategy: "no"
  save_steps: 1000000000
  freeze_modules: ["encoder", "text_decoder"]
  remove_unused_columns: false
  logging_steps: 1
  logging_strategy: "steps"
  optim: adamw_torch
  weight_decay: 1e-3
  max_grad_norm: 1.0
  ddp_find_unused_parameters: false

model:
  speech_encoder_name_or_path: "microsoft/wavlm-large"
  text_decoder_name_or_path: "meta-llama/Llama-3.2-3B"
  downsample_factor: 5
  conversation_version: "llama_3_1"
  projector_n_layers: 2
  projector_activation: "relu"
  projector_hidden_size: 2048
